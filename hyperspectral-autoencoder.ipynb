{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda as cuda\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# Cuda active?\n",
    "if cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    print(\"GPU: {}\".format(cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"Cuda unavailable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import csv, numpy as np\n",
    "import os\n",
    "import OpenEXR as exr, Imath\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "####################\n",
    "# Helper functions #\n",
    "####################\n",
    "\n",
    "def readEXRPatch(filepath, channelrange, i, j, shape):\n",
    "    \"\"\"Helper function for reading .exr files from the KAIST dataset.\n",
    "    \"\"\"\n",
    "    pt = Imath.PixelType(Imath.PixelType.HALF)\n",
    "    file = exr.InputFile(filepath)\n",
    "#     print(file.header())\n",
    "    channels = [\"w{}nm\".format(wavelength) for wavelength in channelrange]\n",
    "    imgstrs = file.channels(channels, pt, i, i + shape[0] - 1)\n",
    "    out = np.zeros(shape + (len(channelrange),), dtype=np.float32)\n",
    "    for i, imgstr in enumerate(imgstrs):\n",
    "        red = np.frombuffer(imgstr, dtype=np.float16)\n",
    "        red = np.reshape(red, (shape[0], -1))\n",
    "        out[:,:,i] = red[:,j:j+shape[1]]\n",
    "    return out\n",
    "\n",
    "def readPNGFiles(filedir, filename, channelrange, minwavelength, increment, i, j, shape):\n",
    "    \"\"\"Helper function for reading patches from the set of png files from the CAVE dataset.\n",
    "    \"\"\"\n",
    "    indexes = [int((wavelength-minwavelength)/increment + 1) for wavelength in channelrange]\n",
    "    patch = np.zeros(shape + (len(channelrange),))\n",
    "    for i, index in enumerate(indexes):\n",
    "        img = Image.open(os.path.join(filedir, \"{}_{:02}.png\".format(filename, index)))\n",
    "        # Divide by max val of np.uint16 to normalize image\n",
    "        x = np.array(img, dtype=np.float32)\n",
    "        x = x[i:i+shape[0], j:j+shape[1]]\n",
    "        patch[:,:,i] = x/np.iinfo(np.uint16).max\n",
    "    return patch\n",
    "\n",
    "###########\n",
    "# Dataset #\n",
    "###########\n",
    "# For reference, the csv field names: \n",
    "# fieldnames = [\"type\", \"dir\", \"name\", \"row\", \"col\", \"side\", \"scale\", \"flip\"]\n",
    "\n",
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, csvfile, minwavelength, maxwavelength, transform=None):\n",
    "        \"\"\"Open and load the lines of the csvfile.\"\"\"\n",
    "        self.minwavelength = minwavelength\n",
    "        self.maxwavelength = maxwavelength\n",
    "        self.datahandles = []\n",
    "        with open(csvfile, \"r\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                self.datahandles.append(row)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datahandles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Unpack data entry:\n",
    "        entry = self.datahandles[idx]\n",
    "        filetype = entry[\"type\"]\n",
    "        entry[\"side\"] = int(entry[\"side\"])\n",
    "        entry[\"scale\"] = float(entry[\"scale\"])\n",
    "        entry[\"row\"] = int(entry[\"row\"])\n",
    "        entry[\"col\"] = int(entry[\"col\"])\n",
    "        if filetype == \"exr\":\n",
    "#             print(entry)\n",
    "            # Read reflectance file\n",
    "            filepath = os.path.join(entry[\"dir\"], entry[\"name\"])\n",
    "            patch = readEXRPatch(filepath, range(self.minwavelength, self.maxwavelength+1, 10),\n",
    "                                 entry[\"row\"], entry[\"col\"], \n",
    "                                 (int(entry[\"side\"]/entry[\"scale\"]),\n",
    "                                  int(entry[\"side\"]/entry[\"scale\"])\n",
    "                                 )\n",
    "                                )\n",
    "            \n",
    "        elif filetype == \"png\":\n",
    "            # Read all the png files\n",
    "            print(\"duh\")\n",
    "            patch = readPNGFiles(entry[\"dir\"], entry[\"name\"], range(self.minwavelength, self.maxwavelength+1, 10),\n",
    "                                 400, 10, \n",
    "                                 entry[\"row\"], entry[\"col\"],\n",
    "                                 (int(entry[\"side\"]/entry[\"scale\"]),\n",
    "                                  int(entry[\"side\"]/entry[\"scale\"])\n",
    "                                 )                                \n",
    "                                )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid data entry at row {} - Cannot load data of type '{}'.\".format(idx, dtype))\n",
    "            \n",
    "        # Resizing\n",
    "        anti_aliasing = True if entry[\"scale\"] < 1 else False\n",
    "        patch = resize(patch, (entry[\"side\"], entry[\"side\"], patch.shape[2]), mode=\"constant\")\n",
    "            \n",
    "        # Flip if necessary:\n",
    "        if entry[\"flip\"]:\n",
    "            patch = np.flip(patch, axis = 1) # Horizontal flip\n",
    "        # Numpy images are (H, W, C)\n",
    "        # But torch needs (C, H, W)\n",
    "        patch = patch.transpose(2, 0, 1)\n",
    "        patch = torch.from_numpy(patch.copy()).type(dtype)\n",
    "\n",
    "        return patch\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "# Hyperparameters\n",
    "height = 96\n",
    "width = 96\n",
    "inchannels = 29\n",
    "outchannels = 64\n",
    "filtersize = 3\n",
    "nlayers = 11\n",
    "samepad = int((filtersize-1)/2)\n",
    "\n",
    "###########\n",
    "# Encoder #\n",
    "###########\n",
    "encoderLayers = [nn.Conv2d(inchannels, outchannels, filtersize, padding=samepad)]\n",
    "for i in range(nlayers):\n",
    "    encoderLayers += [nn.ReLU(), nn.Conv2d(outchannels, outchannels, filtersize, padding=samepad)]\n",
    "Encoder = nn.Sequential(*encoderLayers)\n",
    "\n",
    "###########\n",
    "# Decoder #\n",
    "########### \n",
    "decoderLayers = [] \n",
    "for i in range(nlayers-1):\n",
    "    decoderLayers += [nn.ReLU(), nn.Conv2d(outchannels, outchannels, filtersize, padding=samepad)]\n",
    "decoderLayers += [nn.ReLU(), nn.Conv2d(outchannels, inchannels, filtersize, padding=samepad), nn.ReLU()]\n",
    "Decoder = nn.Sequential(*decoderLayers)\n",
    "\n",
    "###############\n",
    "# Autoencoder #\n",
    "###############\n",
    "Autoencoder = nn.Sequential(OrderedDict([\n",
    "    (\"Encoder\", Encoder),\n",
    "    (\"Decoder\", Decoder)])\n",
    ")\n",
    "\n",
    "# Activate Cuda\n",
    "if cuda.is_available():\n",
    "    Autoencoder.cuda()\n",
    "# Extract layer weights for regularization\n",
    "weights = []\n",
    "for layer in Autoencoder[0]:\n",
    "    try:\n",
    "        weights.append(layer.weight)\n",
    "    except:\n",
    "        pass\n",
    "for layer in Autoencoder[1]:\n",
    "    try:\n",
    "        weights.append(layer.weight)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080\n",
      "epoch: 0\n",
      "\titeration: 0\n",
      "\titeration: 10\n",
      "\titeration: 20\n",
      "\titeration: 30\n",
      "\titeration: 40\n",
      "\titeration: 50\n",
      "\titeration: 60\n",
      "\titeration: 70\n",
      "\titeration: 80\n",
      "\titeration: 90\n",
      "\titeration: 100\n",
      "\titeration: 110\n",
      "\titeration: 120\n",
      "\titeration: 130\n",
      "\titeration: 140\n",
      "\titeration: 150\n",
      "epoch: 1\n",
      "\titeration: 0\n",
      "\titeration: 10\n",
      "\titeration: 20\n",
      "\titeration: 30\n",
      "\titeration: 40\n",
      "\titeration: 50\n",
      "\titeration: 60\n",
      "\titeration: 70\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "lam = 1e-8 # Weight decay parameter for L2 regularization\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 60\n",
    "batch_size = 64\n",
    "\n",
    "########\n",
    "# Data #\n",
    "########\n",
    "train_data = HyperspectralDataset(\"data/kaist_set/kaist_train.csv\", 420, 700)\n",
    "# dataset[286]\n",
    "print(len(train_data))\n",
    "train_data = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(Autoencoder.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40], gamma=0.1)\n",
    "\n",
    "# Loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# Checkpointing\n",
    "best_loss = torch.FloatTensor([float('inf')])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch: {}\".format(epoch))\n",
    "    scheduler.step()\n",
    "    for it, data in enumerate(train_data):\n",
    "        \n",
    "#         print(data)\n",
    "        data = Variable(data, requires_grad=False)\n",
    "        # New batch\n",
    "        scheduler.optimizer.zero_grad()\n",
    "        outimage = Autoencoder(data)\n",
    "        out = 0.5*loss(outimage, data)\n",
    "        for weight in weights:\n",
    "            out += lam*weight.norm()\n",
    "        out.backward()\n",
    "        scheduler.optimizer.step()\n",
    "        if (it % 10):\n",
    "            print(\"\\titeration: {}\\tloss: {}\".format(it, out))\n",
    "        # Checkpointing\n",
    "            # Get bool not ByteTensor\n",
    "    is_best = bool(acc.numpy() > best_accuracy.numpy())\n",
    "    # Get greater Tensor to keep track best acc\n",
    "    best_accuracy = torch.FloatTensor(max(acc.numpy(), best_accuracy.numpy()))\n",
    "    # Save checkpoint if is a new best\n",
    "    save_checkpoint({\n",
    "        'epoch': start_epoch + epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_accuracy': best_accuracy\n",
    "    }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='/output/checkpoint.pth.tar'):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best:\n",
    "        print (\"=> Saving a new best\")\n",
    "        torch.save(state, filename)  # save checkpoint\n",
    "    else:\n",
    "        print (\"=> Validation Accuracy did not improve\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable(cuda.FloatTensor([[1,2],[3,4]]))\n",
    "b = Variable(cuda.FloatTensor([[4, 3], [2, 1]]))\n",
    "loss = 0.5*LossFn(a, b)\n",
    "print(type(loss))\n",
    "weights = []\n",
    "Autoencoder.cuda()\n",
    "for layer in Autoencoder[0]:\n",
    "    try:\n",
    "        weights.append(layer.weight)\n",
    "    except:\n",
    "        pass\n",
    "for layer in Autoencoder[1]:\n",
    "    try:\n",
    "        weights.append(layer.weight)\n",
    "    except:\n",
    "        pass\n",
    "for weight in weights:\n",
    "    loss += weight.norm()\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(id(weights[0]))\n",
    "print(id(Autoencoder[0][0].weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Conv2d(3, 2, 3, 1)\n",
    "layer2 = nn.ReLU()\n",
    "# print(list(layer.parameters())[0])\n",
    "# print(list(layer2.parameters()))\n",
    "for i in Autoencoder[0]:\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = readEXRPatch(\"data/KAIST/scene01_reflectance.exr\", range(420, 721, 10), 1000, 1000, (96, 96))\n",
    "red[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "filedir = \"data/CAVE/\"\n",
    "filename=\"balloons_ms\"\n",
    "i = 3\n",
    "img = Image.open(os.path.join(filedir, filename, filename, \"{}_{:02}.png\".format(filename, i)))\n",
    "x = readPNGFiles(filedir, filename, range(400, 701, 10), 400, 10, 30, 30, (96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x/np.iinfo(np.uint16).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2167/65535\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flip(z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(3)/int(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.Resize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Image.fromarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
